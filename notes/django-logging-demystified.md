## Django Logging Demystified
### by Lee Trout
---

[talk repo](https://github.com/leetrout/djangocon-us-2022)

- Overview
  - What is logging
  - Django/Python logging setup
  - Structured logging
- Logging in Django
  - it's just vanilla Python logging
  - configured via settings module, `dictConfig`
- What is logging?
  - recording information (events, insights/data, unexpected behavior)
- Why do we log? Who do we log for?
  - Understanding
  - Written by people for people
- Observability
  - three pillars
    - logs
    - metrics
    - traces
  - logging can get you most of what you need
  - use performance monitoring services for metrics/traces
    - Sentry, Datadog, New Relic, HoneyComb, etc
  - Logging is a feature; observability is a capability
- Logging in Python
  - logger creates log records
  - log records get passed to handlers
  - handlers use formatters that control the output
  - Primary components
    - records
    - loggers
    - handlers
    - filters
    - formatters
    - levels
    - Levels
      - 0 - `NOTSET`
      - 10 - `DEBUG`
      - 20 - `INFO`
      - 30 - `WARNING` | `WARN`
      - 40 - `ERROR`
      - 50 - `CRITICAL` | `FATAL` 
    - Loggers
      - `logger = logging.getLogger("foo")`
        - creates named logger
      - `logger = logging.getLogger()`
        - root logger
      - you should use string interpolation `logger.info("order with %d items", len(order.items))`
        - f-string vs string interpolation make different log records
        - string interpolation better for third party services because they can group your messages better
          - `record.msg` - `order with %d items`
          - `record.args` - `(2,)`
          - every log message looks the same
            - not true with f-string logs!
    - Hierarchy
      - uses dot notation
      - every logger is descendant as root logger
      - `logger.propagate = False` will not bubble up message to parent loggers 
      - Default level inherited from parent
        - what's the root logger level?
      - filters on loggers are not inherited
    - Log Record
      - contain all information about logging event
      - you don't instantiate these yourself; `logger.info` will create these for you
      - attributes are used to format your log output
    - Handlers
      - used for setting levels, filtering, and formatting
      - multiple handlers built in stdlib (console, file, queues, email, http, syslog, etc)
      - handlers can block your program!
    - Filters
      - let you inspect and even mutate log records
      - can make your own custom filter
      - filters can be added to loggers and handlers
    - Formatters
      - work in concert with handlers to give you final output
      - generally a string
      - django server formatter adds a server time
  - Separation of concerns
    - code generating logs
      - doesn't have to care about where it goes
      - (levels and filters)
    - code handling logs
      - levels, filters and formatters
      - doesn't have to care about how it gets its log messages
    - worst case scenario: you grab some library that configures log handling inside library
      - bad idea
      - author of library should just send log messages
      - library consumer should configure where they go
- Configure Logging in Django
  - First Steps
    - tip: copy Django default logging configuration in your settings
  - `dictConfig()`
    - defined schema corresponding to logging components
    - you can load from JSON out of env or file
      - dynamically load configuration
    - `()` key means load configurations from that class
      - those extra items passed as kwargs
  - Default behavior
    - In production, errors are emails to admins if email handler
    - In development, INFO logs and above are reported in console
    - has three handlers (console, django.server, mail)
    - has two loggers (django, django.server)
  - Logger keys are logger names
    - `'loggers': { 'django': {...}, ... }` == `logging.getLogger('django')`
  - Quick tip
    - adding debug log level for `django.db.backends` will surface SQL generated by ORM
    ```
    "django.db.backends": {
        "handlers": ["console"],
        "level": "DEBUG",
        "propagate": False,
    },
    ```
  - Creating loggers
    - Name your logger
      - Use `__name__`
      - Don't use `__name__` in scripts or entry points will be `__main__`
    - Loggers exist in hierarchy based on "dot path"
      - `pizzapro` and `pizzapro.apps` loggers will product duplicate logs unless propagate False used!
- Structured Logging
  - with regular logging, you just toss a log message
  - with structured logging, you start structuring message and context:
    ```
    logger.info("order.received", extra={
        "items": [
            {
                "kind": "pizza",
                "size": "large",
                "toppings": ["cheese", "pepperoni"]
            },
            ...
        ]
    })
    ```
  - Watch out for:
    - sensitive data
    - too many unique attributes
    - large payloads
  - How to see data
    - need to set up a formatter to see extra attributes
  - Advice:
    -  define your events
       -  create rule for fomatting messages
       -  <state|suffix> - `order.items.progress`
          -  has common extra attributes
       -  `*.duration`
          - `duration_ms`, `start_time`, `end_time`
    - Loggers own the context
      - bind data to loggers with a facade class that passes through common data
        ```
        logger = logging.getLogger(__name__)
        ...
        bound_logger = MyBindingLogger(logger, {"job_id": job_id})
        ...
        bound_logger.info("job.started")
        ```
    - pass logger methods around
    - Test your logs
      - stdlib, testcase has [assertLogs](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertLogs)
      - third party lib called [testfixtures](https://pypi.org/project/testfixtures/)
    - Typehint your log context
      - `TypedDict`
      - dataclass
- Q&A
  - how to analyze logs without using a paid service?
    - [SigNoz](https://github.com/SigNoz/signoz)
    - running ELK stack locally?
  - how to rotate logs?
    - use rotating file handler
  - How do you protect around over-logging?
    - easiest fix - raise logging config in production
    - add more specific handlers
    - do sampling